{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "\n",
    "random_seed = 42\n",
    "\n",
    "# 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(random_seed)\n",
    "\n",
    "# 2. Set the `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(random_seed)\n",
    "\n",
    "# 3. Set the `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as np\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "# 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(random_seed)\n",
    " \n",
    "# Set a random seed for PyTorch (for GPU as well)\n",
    "torch.manual_seed(random_seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(random_seed)\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pan21_functions import *\n",
    "import datetime\n",
    "from keras.callbacks import CSVLogger\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib; import pan21_functions as p21; importlib.reload(p21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pan21PyDataset(\"pan21/train\", \"pan21/train\", \"train_ds_uncompressed\").to_file()\n",
    "# Pan21PyDataset(\"pan21/validation\", \"pan21/validation\", \"val_ds_uncompressed\").to_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the files are good\n",
    "def test_load(path, name):\n",
    "    np.load(path)[name]\n",
    "\n",
    "# _ = Parallel(n_jobs=-1)(delayed(test_load)(Path(\"train_ds\") / f\"{i}.npz\", \"batch_x\") for i in tqdm(range(350)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "\n",
    "# start_idx = 0\n",
    "# limit = 5\n",
    "# # limit = len(train_ds)\n",
    "\n",
    "# before = time.time()\n",
    "# for i in range(start_idx, start_idx+limit):\n",
    "#     batch_x, batch_y = train_ds.__getitem__(i, force_compute=True)\n",
    "# after = time.time()\n",
    "# for i in range(start_idx, start_idx+limit):\n",
    "#     batch_x, batch_y = train_ds.__getitem__(i, force_compute=False)\n",
    "# after_after = time.time()\n",
    "\n",
    "# print(f\"Compute: {round((after - before)/limit, 2)}s vs File read: {round((after_after - after)/limit, 2)}s\")\n",
    "# # Compute: 8.95s per batch\n",
    "# # Compute with compression: ~17s\n",
    "# # Uncompressed read: .7s per batch\n",
    "# # Compressed read: 1.6s per batch\n",
    "# # Compressed is 1/10 the size of uncompressed, but takes ~twice as long to precompute and save\n",
    "# # Compressed 512D Fourier takes ~30s per batch\n",
    "# # Compressed 512D Fourier is about 500-700MB per batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, TimeDistributed, Input, Flatten\n",
    "from tensorflow.keras import optimizers, losses, metrics\n",
    "\n",
    "# Code implementation of the RNN for sequence labeling\n",
    "def create_rnn_model(num_labels, embedding_dim, max_input_length):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(max_input_length*2, embedding_dim)))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(num_labels, activation='sigmoid'))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizers.RMSprop(),  # Optimizer\n",
    "        # Loss function to minimize\n",
    "        loss=losses.BinaryCrossentropy(),\n",
    "        # List of metrics to monitor\n",
    "        metrics=[metrics.BinaryAccuracy(), metrics.AUC()],\n",
    "        jit_compile=True\n",
    "    )\n",
    "\n",
    "    return model\n",
    " \n",
    "num_labels = 1\n",
    "embedding_dim = 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_num_ff(train_ds, val_ds, model_name, epochs=5):\n",
    "    max_input_length = train_ds.max_input_length\n",
    "    # print(f\"{max_input_length=}\")\n",
    "\n",
    "    print(model_name)\n",
    "    time_string = f\"{datetime.datetime.now().strftime('%Y_%m_%d-%I_%M_%S_%p')}\"\n",
    "    model_name.mkdir(exist_ok=True)\n",
    "    checkpoint_name_format = time_string + \"_cp-{epoch:02d}.weights.h5\"\n",
    "    checkpoint_path = model_name / checkpoint_name_format\n",
    "    cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        checkpoint_path, \n",
    "        verbose=1, \n",
    "        save_weights_only=True,\n",
    "        # Save weights, every epoch.\n",
    "        save_freq='epoch')\n",
    "\n",
    "    model = create_rnn_model(num_labels, embedding_dim, max_input_length)\n",
    "    csv_logger = CSVLogger(f'{model_name}_{time_string}.log', separator=',', append=False)\n",
    "\n",
    "    already_trained_epochs = 0\n",
    "    if model_name.exists():\n",
    "        checkpoints = list(Path(model_name).glob('*.weights.h5'))\n",
    "        if checkpoints:\n",
    "            already_trained_epochs = len(checkpoints)\n",
    "            model.load_weights(checkpoints[-1])\n",
    "\n",
    "    if DEVICE == \"cuda\":\n",
    "        with tf.device(\"/device:GPU:0\"):\n",
    "            history = model.fit(\n",
    "                train_ds,\n",
    "                epochs=epochs - already_trained_epochs,\n",
    "                validation_data=val_ds,\n",
    "                verbose=1,\n",
    "                callbacks=[csv_logger, cp_callback]\n",
    "            )\n",
    "    else:\n",
    "        history = model.fit(\n",
    "            train_ds,\n",
    "            epochs=epochs - already_trained_epochs,\n",
    "            validation_data=val_ds,\n",
    "            verbose=1,\n",
    "            callbacks=[csv_logger, cp_callback]\n",
    "        )\n",
    "\n",
    "    model.save(f\"{model_name}.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does using the frequency domain spectra provide usefule information?\n",
    "model_dir = Path(f\"models/num_fourier_features\")\n",
    "if not model_dir.exists():\n",
    "    model_dir.mkdir(parents=True)\n",
    "\n",
    "num_fourier_features = [0, 512//4, 512//2, 512]\n",
    "for num_ff in tqdm(num_fourier_features):\n",
    "    fourier_train_ds = p21.Pan21FourierDataset(\"pan21/train\", \"pan21/train\", num_fourier_features=num_ff)\n",
    "    fourier_val_ds = p21.Pan21FourierDataset(\"pan21/validation\", \"pan21/validation\", num_fourier_features=num_ff)\n",
    "\n",
    "    model_name = model_dir / f\"ff_{num_ff}\"\n",
    "\n",
    "    train_model_num_ff(fourier_train_ds, fourier_val_ds, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many epochs should be trained?\n",
    "model_dir = Path(f\"models/num_epochs\")\n",
    "if not model_dir.exists():\n",
    "    model_dir.mkdir(parents=True)\n",
    "\n",
    "num_fourier_features = [0, 512//4]\n",
    "for num_ff in tqdm(num_fourier_features):\n",
    "    train_model_num_ff(num_ff, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does filtering help?\n",
    "model_dir = Path(f\"models/cutoffs\")\n",
    "if not model_dir.exists():\n",
    "    model_dir.mkdir(parents=True)\n",
    "\n",
    "N = 4 # High pass, band stop, band stop, low pass\n",
    "# Frequencies respresented as percent of Nyquist frequency\n",
    "cutoff_frequencies = [(i / N, (i + 1) / N) for i in range(N)]\n",
    "for cutoff in tqdm(cutoff_frequencies):\n",
    "    filter_train_ds = p21.Pan21FourierFilterDataset(\"pan21/train\", \"pan21/train\", cutoff)\n",
    "    filter_val_ds = p21.Pan21FourierFilterDataset(\"pan21/validation\", \"pan21/validation\", cutoff)\n",
    "\n",
    "    model_name = model_dir / f\"{cutoff[0]}_{cutoff[1]}\"\n",
    "\n",
    "    train_model_num_ff(filter_train_ds, filter_val_ds, model_name, epochs = 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
